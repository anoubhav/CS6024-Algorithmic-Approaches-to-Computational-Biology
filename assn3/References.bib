@articles{q1a,
author="Mahajan, Meena
and Nimbhorkar, Prajakta
and Varadarajan, Kasturi",
editor="Das, Sandip
and Uehara, Ryuhei",
title="The Planar k-Means Problem is NP-Hard",
booktitle="WALCOM: Algorithms and Computation",
year="2009",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="274--285",
abstract="In the k-means problem, we are given a finite set S of points in {\$}{\backslash}Re^m{\$}, and integer k{\thinspace}≥{\thinspace}1, and we want to find k points (centers) so as to minimize the sum of the square of the Euclidean distance of each point in S to its nearest center. We show that this well-known problem is NP-hard even for instances in the plane, answering an open question posed by Dasgupta [6].",
isbn="978-3-642-00202-1"
}
@ARTICLE{q1b,
author={J. {Garcia-Diaz} and R. {Menchaca-Mendez} and R. {Menchaca-Mendez} and S. {Pomares Hernández} and J. C. {Pérez-Sansalvador} and N. {Lakouari}},
journal={IEEE Access},
title={Approximation Algorithms for the Vertex K-Center Problem: Survey and Experimental Evaluation},
year={2019},
volume={7},
number={},
pages={109228-109245},
keywords={Approximation algorithms;Heuristic algorithms;Benchmark testing;Clustering algorithms;Optimization;Law enforcement;Licenses;Approximation algorithms;k-center problem;polynomial time heuristics},
doi={10.1109/ACCESS.2019.2933875},
ISSN={},
month={},}

@article{q1c,
    author = {{Wang, Haizhou, and Mingzhou Song. “Ckmeans.1d.dp: Optimal k-means Clustering in One Dimension by Dynamic Programming.” The R journal vol. 3,2 (2011): 29-33.}},
    title = {}
}

@article{q1d,
title = "Efficient algorithms for the one-dimensional k-center problem",
journal = "Theoretical Computer Science",
volume = "592",
pages = "135 - 142",
year = "2015",
issn = "0304-3975",
doi = "https://doi.org/10.1016/j.tcs.2015.05.028",
url = "http://www.sciencedirect.com/science/article/pii/S0304397515004697",
author = "Danny Z. Chen and Jian Li and Haitao Wang",
keywords = "-center, One-dimension, Facility locations, Algorithms, Data structures, 2-D sublist LP queries, Computational geometry",
abstract = "We consider the problem of finding k centers for n weighted points on a real line. This (weighted) k-center problem was solved in O(nlog⁡n) time previously by using Cole's parametric search and other complicated approaches. In this paper, we present an easier O(nlog⁡n) time algorithm that avoids the parametric search, and in certain special cases our algorithm solves the problem in O(n) time. In addition, our techniques involve developing interesting data structures for processing queries that find a lowest point in the common intersection of a certain subset of half-planes. This subproblem is interesting in its own right and our solution for it may find other applications as well."
}
@article{q3c,
title = "Performance guarantees for hierarchical clustering",
journal = "Journal of Computer and System Sciences",
volume = "70",
number = "4",
pages = "555 - 569",
year = "2005",
note = "Special Issue on COLT 2002",
issn = "0022-0000",
doi = "https://doi.org/10.1016/j.jcss.2004.10.006",
url = "http://www.sciencedirect.com/science/article/pii/S0022000004001321",
author = "Sanjoy Dasgupta and Philip M. Long",
keywords = "Hierarchical clustering, Complete linkage, -Center",
abstract = "We show that for any data set in any metric space, it is possible to construct a hierarchical clustering with the guarantee that for every k, the induced k-clustering has cost at most eight times that of the optimal k-clustering. Here the cost of a clustering is taken to be the maximum radius of its clusters. Our algorithm is similar in simplicity and efficiency to popular agglomerative heuristics for hierarchical clustering, and we show that these heuristics have unbounded approximation factors."
}


@article{q4a,
    author = {https://www.genomicseducation.hee.nhs.uk/blog/reference-genome-defining-human-difference/},
    title = {}
}


@article{q4a2,
    author = {https://en.wikipedia.org/wiki/Reference\_genome/},
    title = {}
}

@article{q4a3,
    author = {https://bitesizebio.com/38335/get-to-know-your-reference-genome-grch37-vs-grch38/},
    title = {}
}

@article{q4b,
    author = {http://resources.qiagenbioinformatics.com/manuals/clcgenomicsworkbench/852/index.php?manual=Remove\_duplicate\_mapped\_reads.html},
    title = {}
}

@article{q4c,
    author = {https://galaxyproject.github.io/training-material/topics/variant-analysis/tutorials/exome-seq/tutorial.html\#mapped-reads-postprocessing},
    title = {}
}


@article {q5c,
	author = {Way, Gregory P. and Greene, Casey S.},
	title = {Extracting a Biologically Relevant Latent Space from Cancer Transcriptomes with Variational Autoencoders},
	elocation-id = {174474},
	year = {2017},
	doi = {10.1101/174474},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {The Cancer Genome Atlas (TCGA) has profiled over 10,000 tumors across 33 different cancer-types for many genomic features, including gene expression levels. Gene expression measurements capture substantial information about the state of each tumor. Certain classes of deep neural network models are capable of learning a meaningful latent space. Such a latent space could be used to explore and generate hypothetical gene expression profiles under various types of molecular and genetic perturbation. For example, one might wish to use such a model to predict a tumor{\textquoteright}s response to specific therapies or to characterize complex gene expression activations existing in differential proportions in different tumors. Variational autoencoders (VAEs) are a deep neural network approach capable of generating meaningful latent spaces for image and text data. In this work, we sought to determine the extent to which a VAE can be trained to model cancer gene expression, and whether or not such a VAE would capture biologically-relevant features. In the following report, we introduce a VAE trained on TCGA pan-cancer RNA-seq data, identify specific patterns in the VAE encoded features, and discuss potential merits of the approach. We name our method {\textquotedblleft}Tybalt{\textquotedblright} after an instigative, cat-like character who sets a cascading chain of events in motion in Shakespeare{\textquoteright}s {\textquotedblleft}Romeo and Juliet{\textquotedblright}. From a systems biology perspective, Tybalt could one day aid in cancer stratification or predict specific activated expression patterns that would result from genetic changes or treatment effects.},
	URL = {https://www.biorxiv.org/content/early/2017/10/02/174474},
	eprint = {https://www.biorxiv.org/content/early/2017/10/02/174474.full.pdf},
	journal = {bioRxiv}
}